{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import draw\n",
    "import data_Manager\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from HyperParameters import HP\n",
    "import train_utility as tu\n",
    "import generate as g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 03:26:30.014772 140088147388224 deprecation.py:506] From /home/mario/git/Sketch-rnn/venv/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "decoder_init_stat (Dense)    (None, 1024)              263168    \n",
      "=================================================================\n",
      "Total params: 263,168\n",
      "Trainable params: 263,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model for predicting the inital state \n",
    "batch_z = tf.keras.Input(shape=(HP.latent_dim,))\n",
    "initial_state = tf.keras.layers.Dense(units=(2*HP.dec_hidden_size), activation='tanh', name = \"decoder_init_stat\")(batch_z)\n",
    "latent_to_hidden_state_model = tf.keras.Model(inputs=batch_z, outputs=initial_state)\n",
    "latent_to_hidden_state_model.load_weights(\"model_weight.h5\", by_name = True)\n",
    "latent_to_hidden_state_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 261)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_decoder (LSTM)             [(None, 1, 512), (No 1585152     input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1, 123)       63099       LSTM_decoder[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,648,251\n",
      "Trainable params: 1,648,251\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the LSTM for generating\n",
    "\"\"\"\n",
    "We have 3 input tensor. The input of the LSTM and the hidden states \n",
    "\"\"\"\n",
    "decoder_input = tf.keras.Input(shape=(1, 5 + HP.latent_dim))\n",
    "initial_h_input = tf.keras.Input(shape=(HP.dec_hidden_size,))\n",
    "initial_c_input = tf.keras.Input(shape=(HP.dec_hidden_size,))\n",
    "# now the LSTM\n",
    "decoderLSTM = tf.keras.layers.LSTM(HP.dec_hidden_size, recurrent_dropout=HP.rec_dropout, \n",
    "                                    return_sequences=True, return_state=True, name = \"LSTM_decoder\")\n",
    "\n",
    "# creation of the LSTM\n",
    "decoder_output, h_new, c_new = decoderLSTM(decoder_input, initial_state = [initial_h_input, initial_c_input])\n",
    "# dense to output. THe dimention is, as explained in the paper equal to 3 + 6*M\n",
    "# 6 times M= number of mixture \n",
    "output_dimention = (3 + HP.M * 6)\n",
    "distribution_output = tf.keras.layers.Dense(output_dimention, name = \"output_layer\")(decoder_output)\n",
    "\n",
    "# Now we load the weights from the trained model\n",
    "generator = tf.keras.models.Model([decoder_input, initial_h_input, initial_c_input], outputs =[ distribution_output , h_new, c_new])\n",
    "generator.summary()\n",
    "generator.load_weights(\"model_weight.h5\", by_name = True)\n",
    "generator.build(tf.TensorShape([1, None])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 03:26:30.580835 140088147388224 deprecation.py:506] From /home/mario/git/Sketch-rnn/venv/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0823 03:26:30.582120 140088147388224 deprecation.py:506] From /home/mario/git/Sketch-rnn/venv/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0823 03:26:30.582799 140088147388224 deprecation.py:506] From /home/mario/git/Sketch-rnn/venv/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 200, 5)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BI_LSTM_encoder (Bidirectional) (None, 512)          536576      encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mean_MLP (Dense)                (None, 256)          131328      BI_LSTM_encoder[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "variance_MLP (Dense)            (None, 256)          131328      BI_LSTM_encoder[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 799,232\n",
      "Trainable params: 799,232\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create the encoder that embed the z\n",
    "\"\"\"\n",
    "encoder_input = tf.keras.layers.Input(shape = (HP.max_seq_length, HP.input_dimention), name = \"encoder_input\" )\n",
    "\n",
    "encoderLSTM = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(HP.enc_hidden_size, return_sequences=False,\n",
    "    recurrent_dropout=HP.rec_dropout, name = \"LSTM_encoder\"), merge_mode='concat', name = \"BI_LSTM_encoder\")(encoder_input)\n",
    "\n",
    "hidden_state_mean = tf.keras.layers.Dense(HP.latent_dim, activation='linear', name = \"mean_MLP\")(encoderLSTM)\n",
    "\n",
    "hidden_state_variance = tf.keras.layers.Dense(HP.latent_dim, activation='linear', name = \"variance_MLP\")(encoderLSTM)\n",
    "# Now we load the weights from the trained model\n",
    "encoder = tf.keras.models.Model(encoder_input,[hidden_state_mean, hidden_state_variance])\n",
    "encoder.summary()\n",
    "encoder.load_weights(\"model_weight.h5\", by_name = True)\n",
    "encoder.build(tf.TensorShape([1, None])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = data_Manager.Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = datas.train[12]\n",
    "x_2 = np.expand_dims(x, axis = 0)\n",
    "mean, variance = encoder.predict(x_2)\n",
    "latent = np.random.rand(1,HP.latent_dim)*np.exp(variance/2)+mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39855236 0.30399314 0.2974545 ]\n",
      "[0.39021188 0.31960303 0.29018512]\n",
      "[0.39035997 0.32523933 0.28440064]\n",
      "[0.38784182 0.33646163 0.27569658]\n",
      "[0.39453074 0.3331647  0.2723046 ]\n",
      "[0.3959548 0.3429758 0.2610694]\n",
      "[0.3950973  0.34607977 0.25882295]\n",
      "[0.40409493 0.34427312 0.2516319 ]\n",
      "[0.41250518 0.34065837 0.2468364 ]\n",
      "[0.4200854  0.33679566 0.24311896]\n",
      "end of sketch\n"
     ]
    }
   ],
   "source": [
    "seq =  g.generate_sketch(generator, latent_to_hidden_state_model, latent_variable=latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"61.750679641059236\" version=\"1.1\" width=\"58.912939582850875\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"61.750679641059236\" width=\"58.912939582850875\" x=\"0\" y=\"0\"/><path d=\"M25,30.31466602658081 m5.728416759034339,-2.046895880165889 l1.0407747401847802,0.04670184830267127 0.6860814743329504,-3.314471994717592 m-3.70773212946208,5.103225316668232 l3.124380113105674,-1.8000247240582612 m-4.297202519347852,-0.1055024023277118 m6.3382211450030645,-1.1273937079525813 l-2.3353974296463056,4.310821613183002 -6.0145864624937655,5.369553545546555 l0.0,0.0 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw.draw_strokes(seq, svg_filename=\"stroke_1.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"158.04831676575068\" version=\"1.1\" width=\"182.01539793924445\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"158.04831676575068\" width=\"182.01539793924445\" x=\"0\" y=\"0\"/><path d=\"M74.70222571224531,42.287730682520106 m-4.91128712571594,-0.5893544550859128 l-5.69709306583049,0.19645148502863757 -7.661607916116866,1.9645148502863758 l-9.82257425143188,3.9290297005727517 -7.858059401145503,5.500641580801853 l-6.482899005945041,6.679350490973679 -4.3219326706300265,7.858059401145503 l-2.357417820343651,9.036768311317328 -0.5893544550859128,9.82257425143188 l2.5538693053722885,10.804831676575068 5.500641580801853,11.590637616689618 l6.679350490973679,9.429671281374604 7.26870494605959,6.679350490973679 l6.482899005945041,3.7325782155441143 7.858059401145503,2.1609663353150133 l11.197734646632341,1.3751603952004632 10.411928706517791,0.5893544550859128 l15.126764347205095,-0.39290297005727515 13.555152466975994,-3.3396752454868395 l7.661607916116866,-3.7325782155441143 8.840316826288692,-5.107738610744577 l15.716118802291007,-13.162249496918719 5.500641580801853,-7.26870494605959 l4.125481185601389,-7.072253461030954 3.143223760458201,-8.447413856231417 l0.39290297005727515,-8.643865341260053 -1.9645148502863758,-9.429671281374604 l-6.482899005945041,-14.53740989211918 -2.7503207904009264,-3.536126730515477 l-9.036768311317328,-5.8935445508591275 -14.73386137714782,-5.107738610744577 l-11.590637616689618,-2.7503207904009264 -9.626122766403242,-1.1787089101718256 l-20.823857413035583,4.91128712571594 -11.39418613166098,4.91128712571594 m-14.930312862176457,0.9822574251431879 l0.0,-17.09127919749147 1.3751603952004632,-2.1609663353150133 l5.8935445508591275,5.107738610744577 4.125481185601389,11.001283161603705 m54.613512837961245,-5.304190095773215 l3.536126730515477,-3.9290297005727517 8.250962371202778,-6.286447520916402 l2.5538693053722885,9.233219796345967 1.1787089101718256,8.05451088617414 m-62.66802372413539,23.181275233379235 l0.5893544550859128,2.357417820343651 0.9822574251431879,0.19645148502863757 l0.5893544550859128,-1.3751603952004632 -0.39290297005727515,-2.7503207904009264 l-0.9822574251431879,1.3751603952004632 m30.646431664467464,-2.7503207904009264 l0.9822574251431879,0.7858059401145503 2.9467722754295638,0.0 l-0.39290297005727515,-1.3751603952004632 -0.9822574251431879,-0.39290297005727515 l-0.7858059401145503,0.5893544550859128 m0.7858059401145503,28.68191681418109 l1.1787089101718256,0.9822574251431879 22.59192077829332,1.5716118802291006 l19.64514850286376,0.0 6.286447520916402,-0.5893544550859128 m-49.70222571224531,-0.7858059401145503 l9.036768311317328,1.7680633652577384 16.501924742405556,5.69709306583049 l8.05451088617414,1.5716118802291006 m-34.37900988001158,-9.429671281374604 l3.3396752454868395,7.26870494605959 13.948055437033268,20.430954442978308 l3.9290297005727517,7.858059401145503 m-61.096411843906296,-25.735144538751523 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw.draw_strokes(x, svg_filename=\"stroke_1.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6985842d50f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "for i in range(x):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
