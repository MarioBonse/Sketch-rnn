{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import draw\n",
    "import data_Manager\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from HyperParameters import HP\n",
    "import train as tu\n",
    "import generate as g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0827 02:28:47.802174 139985304876864 deprecation.py:506] From /home/mario/git/Sketch-rnn/venv/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "decoder_init_stat (Dense)    (None, 1024)              263168    \n",
      "=================================================================\n",
      "Total params: 263,168\n",
      "Trainable params: 263,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model for predicting the inital state \n",
    "batch_z = tf.keras.Input(shape=(HP.latent_dim,))\n",
    "initial_state = tf.keras.layers.Dense(units=(2*HP.dec_hidden_size), activation='tanh', name = \"decoder_init_stat\")(batch_z)\n",
    "latent_to_hidden_state_model = tf.keras.Model(inputs=batch_z, outputs=initial_state)\n",
    "latent_to_hidden_state_model.load_weights(\"model/model_weight_carrot_50_epochs.h5\", by_name = True)\n",
    "latent_to_hidden_state_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 261)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_decoder (LSTM)             [(None, 1, 512), (No 1585152     input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1, 123)       63099       LSTM_decoder[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,648,251\n",
      "Trainable params: 1,648,251\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the LSTM for generating\n",
    "\"\"\"\n",
    "We have 3 input tensor. The input of the LSTM and the hidden states \n",
    "\"\"\"\n",
    "decoder_input = tf.keras.Input(shape=(1, 5 + HP.latent_dim))\n",
    "initial_h_input = tf.keras.Input(shape=(HP.dec_hidden_size,))\n",
    "initial_c_input = tf.keras.Input(shape=(HP.dec_hidden_size,))\n",
    "# now the LSTM\n",
    "decoderLSTM = tf.keras.layers.LSTM(HP.dec_hidden_size, recurrent_dropout=HP.rec_dropout, \n",
    "                                    return_sequences=True, return_state=True, name = \"LSTM_decoder\")\n",
    "\n",
    "# creation of the LSTM\n",
    "decoder_output, h_new, c_new = decoderLSTM(decoder_input, initial_state = [initial_h_input, initial_c_input])\n",
    "# dense to output. THe dimention is, as explained in the paper equal to 3 + 6*M\n",
    "# 6 times M= number of mixture \n",
    "output_dimention = (3 + HP.M * 6)\n",
    "distribution_output = tf.keras.layers.Dense(output_dimention, name = \"output_layer\")(decoder_output)\n",
    "\n",
    "# Now we load the weights from the trained model\n",
    "generator = tf.keras.models.Model([decoder_input, initial_h_input, initial_c_input], outputs =[ distribution_output , h_new, c_new])\n",
    "generator.summary()\n",
    "generator.load_weights(\"model/model_weight_carrot_50_epochs.h5\", by_name = True)\n",
    "generator.build(tf.TensorShape([1, None])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 200, 5)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BI_LSTM_encoder (Bidirectional) (None, 512)          536576      encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mean_MLP (Dense)                (None, 256)          131328      BI_LSTM_encoder[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "variance_MLP (Dense)            (None, 256)          131328      BI_LSTM_encoder[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 799,232\n",
      "Trainable params: 799,232\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create the encoder that embed the z\n",
    "\"\"\"\n",
    "encoder_input = tf.keras.layers.Input(shape = (HP.max_seq_length, HP.input_dimention), name = \"encoder_input\" )\n",
    "\n",
    "encoderLSTM = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(HP.enc_hidden_size, return_sequences=False,\n",
    "    recurrent_dropout=HP.rec_dropout, name = \"LSTM_encoder\"), merge_mode='concat', name = \"BI_LSTM_encoder\")(encoder_input)\n",
    "\n",
    "hidden_state_mean = tf.keras.layers.Dense(HP.latent_dim, activation='linear', name = \"mean_MLP\")(encoderLSTM)\n",
    "\n",
    "hidden_state_variance = tf.keras.layers.Dense(HP.latent_dim, activation='linear', name = \"variance_MLP\")(encoderLSTM)\n",
    "# Now we load the weights from the trained model\n",
    "encoder = tf.keras.models.Model(encoder_input,[hidden_state_mean, hidden_state_variance])\n",
    "encoder.summary()\n",
    "encoder.load_weights(\"model/model_weight_carrot_50_epochs.h5\", by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP.data_location = \"data/carrot.npz\"\n",
    "datas = data_Manager.Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"180.53114059187038\" version=\"1.1\" width=\"172.54409527593424\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"180.53114059187038\" width=\"172.54409527593424\" x=\"0\" y=\"0\"/><path d=\"M25.228201294741034,153.93373152868318 m-0.22820129474103215,-3.19481812637445 l2.738415536892386,-7.302441431713029 18.02790228454154,-39.47882399019856 l3.6512207158565144,-6.617837547489933 3.6512207158565144,-5.248629779043739 l5.933233663266836,-6.617837547489933 28.296960547887988,-28.296960547887988 l15.97409063187225,9.356253084382319 -0.4564025894820643,7.074240136971997 l-1.597409063187225,5.476831073784772 -7.7588440211950935,15.745889337131219 l-14.833084158167091,19.1689087582467 -29.666168316334183,34.45839550589586 l-4.792227189561675,4.107623305338579 -11.181863442310576,2.966616831633418 l-0.22820129474103215,-3.6512207158565144 0.6846038842230965,-1.597409063187225 m55.68111591681185,-94.47533602278732 l1.369207768446193,-5.933233663266836 7.530642726454062,-13.235675094979866 l7.530642726454062,-10.497259558087478 m-19.1689087582467,38.566018811234436 l0.0,-4.564025894820643 2.966616831633418,-4.107623305338579 l19.1689087582467,-23.961135947808376 3.423019421115482,-2.738415536892386 l3.19481812637445,-1.369207768446193 m-18.94070746350567,30.80717479003934 l17.343298400318446,-13.007473800238833 9.812655673864382,-6.1614349580078684 l13.463876389720896,-5.476831073784772 5.476831073784772,-0.9128051789641286 m-39.47882399019856,29.43796702159315 l2.0538116526692893,-2.510214242151354 25.330343716254568,-5.933233663266836 l13.235675094979866,-1.8256103579282572 m-39.022421400716496,5.705032368525804 l21.907324295139087,-7.7588440211950935 11.638266031792641,-6.1614349580078684 l3.6512207158565144,-2.738415536892386 m-41.30443434812682,11.181863442310576 l-0.6846038842230965,-2.0538116526692893 18.02790228454154,-19.39711005298773 l2.966616831633418,-6.1614349580078684 m-31.71997996900347,28.75336313737005 l2.510214242151354,-4.107623305338579 20.994519116174956,-24.189337242549406 m-30.122570905816247,27.384155368923857 l0.22820129474103215,-6.1614349580078684 5.248629779043739,-15.061285452908123 m-8.44344790541819,22.59192817936218 l0.0,-7.530642726454062 2.0538116526692893,-5.705032368525804 l8.215246610677157,-15.289486747649153 m4.564025894820643,38.10961622175237 l2.510214242151354,-5.933233663266836 8.899850494900253,-14.604882863426058 l5.248629779043739,-6.617837547489933 5.476831073784772,-5.248629779043739 m-2.0538116526692893,22.36372688462115 l18.712506168764637,-7.7588440211950935 5.476831073784772,-1.597409063187225 l9.128051789641287,-0.4564025894820643 m-37.65321363227031,23.276532063585282 l2.0538116526692893,-1.369207768446193 6.846038842230964,-1.369207768446193 l20.081713937210832,-7.530642726454062 m-27.840557958405924,2.966616831633418 l26.699551484700763,-4.107623305338579 m-65.26557029593519,7.530642726454062 l8.44344790541819,3.6512207158565144 17.343298400318446,4.792227189561675 m-26.014947600477665,3.19481812637445 l7.7588440211950935,3.423019421115482 10.269058263346446,2.966616831633418 m-25.78674630573663,7.530642726454062 l10.040856968605416,5.020428484302708 7.7588440211950935,2.738415536892386 m-26.471350189959733,6.617837547489933 l14.833084158167091,5.020428484302708 7.530642726454062,0.6846038842230965 m-34.00199291641379,8.671649200159223 l0.9128051789641286,1.369207768446193 2.738415536892386,0.6846038842230965 l14.376681568685026,1.1410064737051608 m-26.2431488952187,13.235675094979866 l4.792227189561675,4.564025894820643 2.966616831633418,1.369207768446193 l15.289486747649153,2.738415536892386 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x = datas.train[12]\n",
    "x_2 = np.expand_dims(x, axis = 0)\n",
    "mean, variance = encoder.predict(x_2)\n",
    "latent = np.random.rand(1,HP.latent_dim)*np.exp(variance/2)+mean\n",
    "draw.draw_strokes(x, svg_filename=\"stroke_1.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of sketch\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"140.7314612076755\" version=\"1.1\" width=\"97.14643514683064\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"140.7314612076755\" width=\"97.14643514683064\" x=\"0\" y=\"0\"/><path d=\"M37.72627967077195,67.31798769117762 m9.191746585315173,14.596172423398844 l6.756055095997257,12.974284873906337 8.220419047941569,8.740924405070336 l3.730275586619677,8.81771988106447 4.283313177856527,3.28437193305788 l1.0602653968196372,-0.38853740990151264 0.7600754716927316,-2.979788745692661 l0.4180051138161168,-16.22748518842558 -2.4658333826545653,-11.188760794735693 l-5.8783388371406815,-15.555017055659787 -1.4456038302134457,-6.607209321088233 l-2.3417302527335013,-6.504643972058679 -2.558535139816154,-5.747613739819282 l-2.1000437861098056,1.2136176431659207 -12.133147172670098,7.525544946168431 l-6.040699950206688,4.551962979590265 -1.1048070773162786,4.349311243482899 l0.2881335801550343,4.324638213949366 m6.551085944438591,-13.555907055666525 l-1.8859946239567362,-1.046872792717043 -3.318456626833959,-7.297087099088273 l-3.354540172994355,-1.8251842652396866 -8.124469665708023,-2.271291661308719 l-1.2334541530699674,-0.6473298542636847 0.12451027004607408,-1.2419798731595961 l2.4033205723926843,-0.5986634668801283 2.7865814134264055,-0.4010184953790714 l4.969540996888966,-0.6846779439620739 5.4268865899159096,-0.810290615839547 l2.4332754961001015,3.412090266169238 0.7531466169944219,-1.461403624246254 l-0.9062505941334607,-6.236468426151767 0.768386421332752,-4.357205522270762 l1.7742780904788205,-2.2519400514970678 2.157446998938533,-3.355447869621905 l3.9125085943733393,-2.8668016555280933 1.2434485804610407,0.8851831070122786 l0.5003130117661876,1.2966753164422866 1.045241996654124,6.6238851656048565 l0.0007557861542565464,6.97426230976241 -0.7650228806889394,3.562417789914547 l-4.362961412115101,7.730036195788546 -0.7618529304149796,3.406833207773177 l0.04428779395430498,3.5755365856612906 1.1105190565490268,0.4576980688668206 m-10.384879936422955,16.56387583739115 l7.67375869373724,-1.1229674414005832 7.675823188080632,-2.9459813898147456 m-7.550270777179083,12.763504538817715 l11.772715215276785,-5.544286938789479 m-5.272441816441258,14.387963197316704 l6.606506751857597,-3.498172967158573 m0.0,0.0 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq =  g.generate_sketch(generator, latent_to_hidden_state_model, temperature=0.2)\n",
    "draw.draw_strokes(seq, svg_filename=\"results/carrot.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
